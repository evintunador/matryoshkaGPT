{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd290691-bd0f-4ef8-8225-83c735dc3a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/tunadorable/local-repos/ng-video-lecture/venv/lib/python3.11/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3178c0b6-30f1-45c4-8710-df38c849673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import time\n",
    "from typing import List\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "110af9c3-ac21-4e15-8806-8ac1de98aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86bacbe-ac30-42fa-aaed-53f527a00a8a",
   "metadata": {},
   "source": [
    "# Thinking about how layernorm affects these hierarchical vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd385213-e031-4fc9-b69c-6edbe817b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "### gotta turn this into a way to keep each sub-vector on the unit hypersphere\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "def adjust_and_concatenate(v1, v2):\n",
    "    \"\"\"\n",
    "    Concatenates two vectors and adjusts the second vector so that the entire concatenated vector\n",
    "    is normally distributed with a mean of 0 and standard deviation of 1, without altering the first vector.\n",
    "    \n",
    "    Parameters:\n",
    "    - v1: First vector of length 100, already normalized.\n",
    "    - v2: Second vector of length 100, already normalized.\n",
    "    \n",
    "    Returns:\n",
    "    - concatenated_vector: Concatenated vector of length 200, with adjusted values for the second half.\n",
    "    \"\"\"\n",
    "    # Step 1: Concatenate the vectors\n",
    "    concatenated_vector = np.concatenate([v1, v2])\n",
    "    \n",
    "    # Step 2: Adjust the second half to maintain overall normal distribution\n",
    "    # Calculate mean and std of the concatenated vector\n",
    "    mean_full = np.mean(concatenated_vector)\n",
    "    std_full = np.std(concatenated_vector)\n",
    "    \n",
    "    # Calculate adjustments needed for the second half\n",
    "    adjustment_factor = 1 / std_full  # To ensure overall std is 1\n",
    "    mean_adjustment = -mean_full * adjustment_factor  # To ensure overall mean is 0\n",
    "    \n",
    "    # Apply adjustments to the second half\n",
    "    concatenated_vector[100:] = concatenated_vector[100:] * adjustment_factor + mean_adjustment\n",
    "    \n",
    "    return concatenated_vector\n",
    "\n",
    "\n",
    "def test_concatenation(concatenated_vector, original_vec1):\n",
    "    \"\"\"\n",
    "    Tests whether the concatenated vector maintains the first 100 values unchanged\n",
    "    and whether the entire 200-element vector follows a normal distribution.\n",
    "\n",
    "    Parameters:\n",
    "    - concatenated_vector: The concatenated and adjusted vector of length 200.\n",
    "    - original_vec1: The original first vector to compare the first 100 values against.\n",
    "\n",
    "    Returns:\n",
    "    - first_half_unchanged: Boolean, True if the first 100 values are unchanged.\n",
    "    - is_normal: Boolean, True if the concatenated vector is normally distributed.\n",
    "    \"\"\"\n",
    "    # Check if the first 100 values are unchanged\n",
    "    first_half_unchanged = np.array_equal(concatenated_vector[:100], original_vec1)\n",
    "\n",
    "    # Test for normality on the entire vector\n",
    "    stat, p = shapiro(concatenated_vector)\n",
    "    is_normal = p > 0.05  # Using a significance level of 0.05\n",
    "\n",
    "    return first_half_unchanged, is_normal\n",
    "\n",
    "# Example usage with dummy data\n",
    "vec1 = np.random.normal(0, 1, 100)  # First vector, normalized\n",
    "vec2 = np.random.normal(0, 1, 100)  # Second vector, normalized\n",
    "\n",
    "# Concatenate and adjust\n",
    "concatenated_vector = adjust_and_concatenate(vec1, vec2)\n",
    "\n",
    "# Test the concatenation\n",
    "first_half_unchanged, is_normal = test_concatenation(concatenated_vector, vec1)\n",
    "\n",
    "first_half_unchanged, is_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8aa250-883b-4c8f-8f3b-b2133d1b4f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import shapiro, norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to generate random vectors using different distributions\n",
    "def generate_random_vectors(length, n_vectors):\n",
    "    vectors = {\n",
    "        \"normal\": np.random.normal(size=(n_vectors, length)),\n",
    "        \"uniform\": np.random.uniform(size=(n_vectors, length)),\n",
    "        \"exponential\": np.random.exponential(scale=1.0, size=(n_vectors, length)),\n",
    "        # Add more distributions if needed\n",
    "    }\n",
    "    return vectors\n",
    "\n",
    "# Function to apply layer normalization to vectors\n",
    "def layer_normalize(vectors):\n",
    "    normed_vectors = {}\n",
    "    for key, vecs in vectors.items():\n",
    "        mean = np.mean(vecs, axis=1, keepdims=True)\n",
    "        std = np.std(vecs, axis=1, keepdims=True)\n",
    "        normed_vectors[key] = (vecs - mean) / std\n",
    "    return normed_vectors\n",
    "\n",
    "# Function to create subsets and test for normality\n",
    "def test_subsets_for_normality(vectors, max_length):\n",
    "    results = {}\n",
    "    subset_lengths = [2**i for i in range(3, int(np.log2(max_length))+1)]  # 8, 16, 32, ..., up to max_length\n",
    "    for key, vecs in vectors.items():\n",
    "        results[key] = {}\n",
    "        for length in subset_lengths:\n",
    "            p_values = []\n",
    "            for vec in vecs:\n",
    "                subset = vec[:length]\n",
    "                _, p_value = shapiro(subset)\n",
    "                p_values.append(p_value)\n",
    "            results[key][length] = np.mean(p_values)\n",
    "    return results\n",
    "\n",
    "# Parameters\n",
    "length = 1024\n",
    "n_vectors = 1000  # Number of vectors for each distribution\n",
    "\n",
    "# Generate random vectors\n",
    "random_vectors = generate_random_vectors(length, n_vectors)\n",
    "\n",
    "# Apply layer normalization\n",
    "normalized_vectors = layer_normalize(random_vectors)\n",
    "\n",
    "# Test subsets for normality\n",
    "results = test_subsets_for_normality(normalized_vectors, length)\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0977d36-7291-4aa1-8cfd-15ea7acdd7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot histograms for original and normalized vectors\n",
    "def plot_histograms(original_vectors, normalized_vectors, distribution):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n",
    "    fig.suptitle(f'{distribution.capitalize()} Distribution: Before and After Normalization')\n",
    "\n",
    "    # Original Vector Histogram\n",
    "    axes[0].hist(original_vectors[distribution][0], bins=30, alpha=0.7, color='blue')\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].set_xlabel('Value')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "\n",
    "    # Normalized Vector Histogram\n",
    "    axes[1].hist(normalized_vectors[distribution][0], bins=30, alpha=0.7, color='green')\n",
    "    axes[1].set_title('Normalized')\n",
    "    axes[1].set_xlabel('Value')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot for each distribution\n",
    "for distribution in [\"normal\", \"uniform\", \"exponential\"]:\n",
    "    plot_histograms(random_vectors, normalized_vectors, distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af353846-9aff-48ad-930d-0d426e586993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Euclidean norms for vectors\n",
    "def calculate_norms(vectors):\n",
    "    norms = {}\n",
    "    for key, vecs in vectors.items():\n",
    "        norms[key] = np.linalg.norm(vecs, axis=1)  # Euclidean norm (L2 norm) of each vector\n",
    "    return norms\n",
    "\n",
    "# Calculate norms for original and normalized vectors\n",
    "original_norms = calculate_norms(random_vectors)\n",
    "normalized_norms = calculate_norms(normalized_vectors)\n",
    "\n",
    "# Plotting the magnitudes using box plots\n",
    "def plot_magnitude_comparison(original_norms, normalized_norms):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    distributions = ['normal', 'uniform', 'exponential']\n",
    "\n",
    "    for i, distribution in enumerate(distributions):\n",
    "        # Combine original and normalized norms for plotting\n",
    "        data = [original_norms[distribution], normalized_norms[distribution]]\n",
    "        axes[i].boxplot(data, patch_artist=True, labels=['Original', 'Normalized'])\n",
    "        axes[i].set_title(f'{distribution.capitalize()} Distribution')\n",
    "        axes[i].set_ylabel('Magnitude (Euclidean Norm)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_magnitude_comparison(original_norms, normalized_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18738ce0-45f6-4a9a-80f7-8c353d39413c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9850e5-8b9c-465b-a6a1-157110cae99d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
