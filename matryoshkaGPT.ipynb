{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01dd2652-6a1d-4ec6-851a-9a622a727c07",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- annotate well so someone reading can understand\n",
    "- make parameter initializations consistent\n",
    "- remove d_i options throughout\n",
    "- figure out generate() to use the submodels\n",
    "- copy the cosine similarity visual exploration tools from `matryoshka_embeddings_gpt`?\n",
    "- train & save a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06403ac1-590b-49e0-94b0-76f3cc5f28b9",
   "metadata": {},
   "source": [
    "#### !!!! DO NOT RUN THIS FIRST CELL UNLESS YOU HAVE THE SAME VENV PATH ISSUE THAT I DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e2810a3-9d58-4654-aa33-b94d6073080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/tunadorable/local-repos/ng-video-lecture/venv/lib/python3.11/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a4d675f-e0c7-4012-9fbe-5b5fb89cd804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import time\n",
    "from typing import List\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a38c82-571d-481b-b080-b07f083fe903",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f521e2e-1c91-4228-85eb-cd86394d0c60",
   "metadata": {},
   "source": [
    "# MatryoshkaGPT\n",
    "\n",
    "the idea here is to have a bunch of tiny models inside the main model like russian nesting dolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac499f0a-a4e9-4eda-bb3b-4c197f8dc8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 16, 32, 64]\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "b = 4 # how many independent sequences will we process in parallel?\n",
    "t = 16 # what is the maximum context length for predictions?\n",
    "max_iters = 10\n",
    "eval_interval = 2\n",
    "lr = 3e-4 # learning rate for each backprop step\n",
    "eval_iters = 20\n",
    "h = 4 # number of attention heads\n",
    "l = 4 # number of transormer layers\n",
    "dropout = 0.1 # % of parameters to ignore every iteration\n",
    "l2 = 0.01 # multiplier for our L2 norm to encourage sparsity\n",
    "\n",
    "# embedding aka hidden dimension. this is the largest that th emodel will have\n",
    "d = 64\n",
    "power_of_d = int(math.log2(d))\n",
    "# the smallest power of 2 we'll be considering as a matryoshka embedding\n",
    "min_power = 3 # Starting from 2^min_power\n",
    "nesting_list = [2**i for i in range(min_power, int(power_of_d) + 1)]\n",
    "print(nesting_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c387e1ff-0f75-446a-8c17-2c59e6d48ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d6d2a96-ae95-43ab-a9b6-6a17e0c12d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'] 65\n"
     ]
    }
   ],
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "v = len(chars)\n",
    "print(chars, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9496b4a1-6b4c-4166-8be6-8108d61b3c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17e88e17-a1cf-4a4a-a762-47e365864970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f74d39e-ff60-4dc4-a98e-59a76f5cab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - t, (b,))\n",
    "    x = torch.stack([data[i:i+t] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+t+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8152bb8-23de-4f45-b91a-503da6763209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x  torch.Size([4, 16]) \n",
      " tensor([[43, 56,  1, 51, 39, 52,  0, 31, 47, 45, 46,  5, 42,  1, 58, 56],\n",
      "        [42,  1, 52, 53, 61,  1, 61, 46, 47, 50, 57, 58,  1, 21,  1, 50],\n",
      "        [57, 43, 42, 11,  1, 57, 43, 58,  1, 53, 52,  8,  1, 32, 46, 47],\n",
      "        [43, 57, 58, 43, 56, 52,  1, 57, 46, 53, 56, 43,  8,  0, 31, 39]])\n",
      "y  torch.Size([4, 16]) \n",
      " tensor([[56,  1, 51, 39, 52,  0, 31, 47, 45, 46,  5, 42,  1, 58, 56, 59],\n",
      "        [ 1, 52, 53, 61,  1, 61, 46, 47, 50, 57, 58,  1, 21,  1, 50, 47],\n",
      "        [43, 42, 11,  1, 57, 43, 58,  1, 53, 52,  8,  1, 32, 46, 47, 57],\n",
      "        [57, 58, 43, 56, 52,  1, 57, 46, 53, 56, 43,  8,  0, 31, 39, 44]])\n"
     ]
    }
   ],
   "source": [
    "# so you can see what the tokenized data looks like\n",
    "x,y = get_batch('train')\n",
    "print(\"x \", x.shape, \"\\n\", x)\n",
    "print(\"y \", y.shape, \"\\n\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fe93f11-1538-44fb-9a15-f3e635f902b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval() # sets model to eval mode\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train() # just resets to training mode\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c1f05b-6bb9-492e-a935-5079b13a2760",
   "metadata": {},
   "source": [
    "# FEEDFORWARD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b9e9bc-3461-4939-b4e1-ad772a4c1894",
   "metadata": {},
   "source": [
    "class matryoshkaFeedFoward(nn.Module):\n",
    "    def __init__(self, nesting_list: List, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        # the largest embedding dimension of the model\n",
    "        self.d = nesting_list[-1]\n",
    "\n",
    "        # initialize only the largest. we'll subset later during forward()\n",
    "        self.w1 = nn.Linear(self.d, 4 * self.d).to(device)\n",
    "        self.w2 = nn.Linear(4 * self.d, self.d).to(device)\n",
    "\n",
    "        # Initialize only the largest weights and biases\n",
    "        self.w1 = nn.Parameter(torch.Tensor(self.d, 4 * self.d)) # need to double check correct sizes\n",
    "        self.b1 = nn.Parameter(torch.Tensor(4 * self.d))\n",
    "        self.w2 = nn.Parameter(torch.Tensor(4 * self.d, self.d))\n",
    "        self.b2 = nn.Parameter(torch.Tensor(self.d))\n",
    "\n",
    "        # Initializing weights\n",
    "        nn.init.normal_(self.w1, std=0.02)  \n",
    "        nn.init.normal_(self.b1, std=0.02)\n",
    "        nn.init.normal_(self.w2, std=0.02)\n",
    "        nn.init.normal_(self.b2, std=0.02)\n",
    "\n",
    "        # to be used for iterating in forward()\n",
    "        self.nesting_list = nesting_list\n",
    "        \n",
    "        # the other parts\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        # so dropout might become an issue\n",
    "        # dropping out 10% of an 8x8 matrix will have a different effect from dropping out 10% of a 1024x1024 one\n",
    "        # and potentially more importantly, different weights will get dropped out for each nesting doll\n",
    "        # this may actually be beneficial in terms of the model's generalizability, but maybe it'll be bad idk\n",
    "\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        input: tuple of length g with tensors of shape (b,t,d_i) for d_i=nesting_list[i]\n",
    "        output: tuple of length g with tensors of shape (b,t,d_i) for d_i=nesting_list[i]\n",
    "        \"\"\"\n",
    "        # old\n",
    "        #return self.drop(self.w2(self.relu(self.w1(x))))\n",
    "        #print(\"ffwd\")\n",
    "        #print(\"x: \", x[-1].shape)\n",
    "        #print(\"w1: \", self.w1.shape)\n",
    "        #print(\"b1: \", self.b1.shape)\n",
    "        #print(\"w2: \", self.w2.shape)\n",
    "        #print(\"b2: \", self.b2.shape)\n",
    "        out = ()\n",
    "        for i, d_i in enumerate(self.nesting_list): # i is int from 0 to g-1 while d_i=nesting_list[i]\n",
    "            #print(x[i].shape)\n",
    "            #print((x[i]@self.w1[:d_i,:4*d_i]).shape)\n",
    "            #print((x[i] @ self.w1[:d_i,:4*d_i] + self.b1[:4*d_i]).shape)\n",
    "            #print((self.relu(x[i] @ self.w1[:d_i,:4*d_i] + self.b1[:4*d_i])).shape)\n",
    "            #print((self.relu(x[i] @ self.w1[:d_i,:4*d_i] + self.b1[:4*d_i]) @ self.w2[:4*d_i,:d_i]).shape)\n",
    "            #print((self.relu(x[i] @ self.w1[:d_i,:4*d_i] + self.b1[:4*d_i]) @ self.w2[:4*d_i,:d_i] + self.b2[:d_i]).shape)\n",
    "            #print((self.drop(self.relu(x[i] @ self.w1[:d_i,:4*d_i] + self.b1[:4*d_i]) @ self.w2[:4*d_i,:d_i] + self.b2[:d_i])).shape)\n",
    "            out += (self.drop(self.relu(x[i] @ self.w1[:d_i,:4*d_i] + self.b1[:4*d_i]) @ self.w2[:4*d_i,:d_i] + self.b2[:d_i]),)\n",
    "            #print(f\"ffwd out {i}: {out[i].shape}\")\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8d0d110-2328-43f5-bf34-12e1b40070fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class matryoshkaFeedFoward(nn.Module):\n",
    "    def __init__(self, nesting_list: List, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        # the largest embedding dimension of the model\n",
    "        self.d = nesting_list[-1]\n",
    "\n",
    "        # initialize only the largest. we'll subset later during forward()\n",
    "        self.w1 = nn.Linear(self.d, 4 * self.d).to(device)\n",
    "        self.w2 = nn.Linear(4 * self.d, self.d).to(device)\n",
    "\n",
    "        # Initialize only the largest weights and biases\n",
    "        self.w1 = nn.Parameter(torch.Tensor(self.d, 4 * self.d)) # need to double check correct sizes\n",
    "        self.b1 = nn.Parameter(torch.Tensor(4 * self.d))\n",
    "        self.w2 = nn.Parameter(torch.Tensor(4 * self.d, self.d))\n",
    "        self.b2 = nn.Parameter(torch.Tensor(self.d))\n",
    "\n",
    "        # Initializing parameters\n",
    "        nn.init.normal_(self.w1, std=0.02)  \n",
    "        nn.init.normal_(self.b1, std=0.02)\n",
    "        nn.init.normal_(self.w2, std=0.02)\n",
    "        nn.init.normal_(self.b2, std=0.02)\n",
    "\n",
    "        # to be used for iterating in forward()\n",
    "        self.nesting_list = nesting_list\n",
    "        \n",
    "        # the other parts\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        # intuitively i think applying dropout this way might actually be better for generalizability of inner-nesting_doll parameters\n",
    "\n",
    "    def forwardTuple(self, x):\n",
    "        \"\"\"\n",
    "        input: tuple of length g with tensors of shape (b,t,d_i) for d_i=nesting_list[i]\n",
    "        operation: 2 linear layers with a 4-times depth, a relu nonlinearity in between, and then a dropout\n",
    "        output: tuple of length g with tensors of shape (b,t,d_i) for d_i=nesting_list[i]\n",
    "        \"\"\"\n",
    "        out = ()\n",
    "        for i, d_i in enumerate(self.nesting_list):\n",
    "            out += (self.drop(self.relu(x[i] @ self.w1[:d_i,:4*d_i] + self.b1[:4*d_i]) @ self.w2[:4*d_i,:d_i] + self.b2[:d_i]),)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def forwardTensor(self, x, d_i=None):\n",
    "        \"\"\"\n",
    "        input: tensor of shape (b,t,d_i) & optionally a specified d_i\n",
    "        operation: 2 linear layers with a 4-times depth, a relu nonlinearity in between, and then a dropout\n",
    "        output: tensor of shape (b,t,d_i)\n",
    "        \"\"\"\n",
    "        if d_i is None:\n",
    "            d_i = x.shape[-1]\n",
    "        return self.drop(self.relu(x @ self.w1[:d_i, :4*d_i] + self.b1[:4*d_i]) @ self.w2[:4*d_i, :d_i] + self.b2[:d_i])\n",
    "    \n",
    "    def forward(self, x, d_i=None):\n",
    "        return self.forwardTuple(x) if type(x) == tuple else self.forwardTensor(x, d_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e78c4ad-5323-43e7-80b8-ebaeede8a15f",
   "metadata": {},
   "source": [
    "# ATTENTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02848ab-71d3-4ed2-bee3-2bdd0b633053",
   "metadata": {},
   "source": [
    "class matryoshkaHead(nn.Module):\n",
    "    def __init__(self, nesting_list: List, head_sizes: List):\n",
    "        super().__init__()\n",
    "        \n",
    "        # the largest embedding dimension of the model\n",
    "        self.d = nesting_list[-1]\n",
    "        # the largest head size\n",
    "        self.h = head_sizes[-1]\n",
    "\n",
    "        # to be used for iterating in forward()\n",
    "        self.nesting_list = nesting_list\n",
    "        self.head_sizes = head_sizes\n",
    "\n",
    "        # initialize only the largest. we'll subset later during forward()\n",
    "        #self.key = nn.Linear(self.d, self.h, bias=False)\n",
    "        self.key = nn.Parameter(torch.Tensor(self.d, self.h)).to(device)\n",
    "        #self.query = nn.Linear(self.d, self.h, bias=False)\n",
    "        self.query = nn.Parameter(torch.Tensor(self.d, self.h)).to(device)\n",
    "        #self.value = nn.Linear(self.d, self.h, bias=False)\n",
    "        self.value = nn.Parameter(torch.Tensor(self.d, self.h)).to(device)\n",
    "\n",
    "        # the mask so they only look into the past\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(t, t))) # mask future timestesps\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self): # i need to make all my parameter initializations consistent instead of using this\n",
    "        a = math.sqrt(5)\n",
    "        nn.init.kaiming_uniform_(self.key, a)  # or any other initialization\n",
    "        nn.init.kaiming_uniform_(self.query, a)\n",
    "        nn.init.kaiming_uniform_(self.value, a)\n",
    "\n",
    "    def forward(self, x_0):\n",
    "        \"\"\"\n",
    "        input: tuple length g with tensors of shape (b,t,d_i) for d_i=nesting_list[i]\n",
    "        output: tuple length g with tensors of shape (b,t,h_i) for h_i=head_sizes[i] where h_i = d_i / h\n",
    "        \"\"\"\n",
    "        #print(\"head\")\n",
    "        #print(\"Wk full: \", self.key.shape) #.weight.shape)\n",
    "        #print(\"Wq full: \", self.query.shape)\n",
    "        #print(\"Wv full: \", self.value.shape)\n",
    "        #b,t,d = x.shape\n",
    "        k,q,v,wei,out = (),(),(),[],()\n",
    "        for i, (d_i, h_i) in enumerate(zip(self.nesting_list, self.head_sizes)):\n",
    "            #print(i)\n",
    "            #print(f\"x_0[{i}]: \", x_0[i].shape)\n",
    "            #print(f\"d_i: {d_i} h_i: {h_i}\")\n",
    "            #Wk = self.key[:d_i, :h_i] #.weight[:d_i, :h_i]\n",
    "            #print(\"Wk: \", Wk.shape)\n",
    "            k += (torch.matmul(x_0[i],self.key[:d_i, :h_i]),)\n",
    "            #Wq = self.query[:d_i, :h_i] #.weight[:d_i, :h_i]\n",
    "            #print(\"Wq: \", Wq.shape)\n",
    "            q += (x_0[i] @ self.query[:d_i, :h_i],)\n",
    "            #Wv = self.value[:d_i, :h_i] #.weight[:d_i, :h_i]\n",
    "            #print(\"Wv: \", Wv.shape)\n",
    "            v += (x_0[i] @ self.value[:d_i, :h_i],)\n",
    "\n",
    "            # not sure if this is a bunch of \"in-place\" operations\n",
    "            # if i get an error about that then what i gotta do is make it separate variables instead of repeatedly editing wei\n",
    "            wei.append(q[i] @ k[i].transpose(-2,-1) * k[i].shape[-1]**-0.5)\n",
    "            wei[i] = wei[i].masked_fill(self.tril[:t,:t] == 0, float('-inf'))\n",
    "            wei[i] = F.softmax(wei[i],dim=-1)\n",
    "            \n",
    "            out += (wei[i]@v[i],)\n",
    "        #print(\"out: \", out[0].shape, out[1].shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca7a137e-ddaa-4e0e-8f2d-3cef77132799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class matryoshkaHead(nn.Module):\n",
    "    def __init__(self, nesting_list: List, head_sizes: List):\n",
    "        super().__init__()\n",
    "        \n",
    "        # the largest embedding dimension of the model\n",
    "        self.d = nesting_list[-1]\n",
    "        # the largest head size\n",
    "        self.h = head_sizes[-1]\n",
    "\n",
    "        # to be used for iterating in forward()\n",
    "        self.nesting_list = nesting_list\n",
    "        self.head_sizes = head_sizes\n",
    "\n",
    "        # initialize only the largest. we'll subset later during forward()\n",
    "        self.key = nn.Parameter(torch.Tensor(self.d, self.h)).to(device)\n",
    "        self.query = nn.Parameter(torch.Tensor(self.d, self.h)).to(device)\n",
    "        self.value = nn.Parameter(torch.Tensor(self.d, self.h)).to(device)\n",
    "        \n",
    "        # Initializing parameters\n",
    "        nn.init.normal_(self.key, std=0.02)  \n",
    "        nn.init.normal_(self.query, std=0.02)\n",
    "        nn.init.normal_(self.value, std=0.02)\n",
    "\n",
    "        # the mask so they only look into the past\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(t, t))) # mask future timestesps\n",
    "\n",
    "    def forwardTuple(self, x):\n",
    "        \"\"\"\n",
    "        input: tuple length g with tensors of shape (b,t,d_i) for d_i=nesting_list[i]\n",
    "        operation: masked self-attention\n",
    "        output: tuple length g with tensors of shape (b,t,h_i) for h_i=head_sizes[i] where h_i = d_i / h\n",
    "        \"\"\"\n",
    "        k,q,v,wei,out = (),(),(),[],()\n",
    "        for i, (d_i, h_i) in enumerate(zip(self.nesting_list, self.head_sizes)):\n",
    "            k += (x[i] @ self.key[:d_i, :h_i],)\n",
    "            q += (x[i] @ self.query[:d_i, :h_i],)\n",
    "            v += (x[i] @ self.value[:d_i, :h_i],)\n",
    "\n",
    "            wei.append(q[i] @ k[i].transpose(-2,-1) * k[i].shape[-1]**-0.5) # is k[i].shape[-1] the same as h_i?\n",
    "            wei[i] = wei[i].masked_fill(self.tril[:t,:t] == 0, float('-inf'))\n",
    "            wei[i] = F.softmax(wei[i],dim=-1)\n",
    "            \n",
    "            out += (wei[i]@v[i],)\n",
    "        #print(\"out: \", out[0].shape, out[1].shape)\n",
    "        return out\n",
    "\n",
    "    def forwardTensor(self, x, d_i, h):\n",
    "        \"\"\"\n",
    "        input: \n",
    "            - tensor of shape (b,t,d_i)\n",
    "            - dimension to use d_i\n",
    "            - number of heads h\n",
    "        operation: masked self-attention\n",
    "        output: tensor of shape (b,t,h_i) where h_i = d_i / h\n",
    "        \"\"\"\n",
    "        if d_i is None:\n",
    "            d_i = x.shape[-1]\n",
    "\n",
    "        h_i = d_i // h\n",
    "\n",
    "        k = x @ self.key[:d_i, :h_i]\n",
    "        q = x @ self,query[:d_i, :h_i]\n",
    "        v = x @ self.value[:d_i, :h_i]\n",
    "\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5\n",
    "        wei = wei.masked_fill(self.tril[:t,:t] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "        return wei@v\n",
    "        \n",
    "    def forward(self, x, d_i=None, h=None):\n",
    "        return self.forwardTuple(x) if type(x) == tuple else self.forwardTensor(x, d_i, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093fe357-1ee7-4017-a356-d033b90eb71f",
   "metadata": {},
   "source": [
    "# MHA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160d73a6-3ff5-4dd8-a4bb-2990eb724c70",
   "metadata": {},
   "source": [
    "class matryoshkaMultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, h, nesting_list: List, head_sizes: List, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.nesting_list = nesting_list\n",
    "        self.head_sizes = head_sizes\n",
    "        self.h_count = h # number of heads\n",
    "        self.d_count = len(nesting_list) # number of nesting doll sizes\n",
    "        self.h_max = head_sizes[-1] # size of largest head\n",
    "        self.d_max = nesting_list[-1]\n",
    "        \n",
    "        # can you have tuples inside a module list? i hope so\n",
    "        self.headsList = nn.ModuleList([matryoshkaHead(self.nesting_list, self.head_sizes) for _ in range(self.h_count)])\n",
    "        \n",
    "        #self.proj = nn.Linear(head_sizes[-1] * h, nesting_list[-1])\n",
    "        # the linear projection that combines the outputs of all the heads\n",
    "        self.weight = nn.Parameter(torch.Tensor(self.h_max * self.h_count, self.d_max)).to(device)\n",
    "        self.bias = nn.Parameter(torch.Tensor(self.h_max * self.h_count)).to(device)\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        self.reset_parameters()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def reset_parameters(self): # i need to make all my parameter initializations consistent instead of using this\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))  # or any other initialization\n",
    "        fan_in1, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "        bound1 = 1 / math.sqrt(fan_in1)\n",
    "        nn.init.uniform_(self.bias, -bound1, bound1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        input: tuple of length g with tensors of shape (b,t,d_i) for d_i=nesting_list[i]\n",
    "            input to each head: tuple of length g with tensors of shape (b,t,d_i) for d_i=nesting_list[i]\n",
    "            output from each head: tuple length g with tensors of shape (b,t,h_i) for h_i=head_sizes[i] where h_i = d_i / h\n",
    "        output: tuple of length g with tensors of shape (b,t,d_i) for d_i=nesting_list[i]\n",
    "        \"\"\"\n",
    "        #print(\"mha\")\n",
    "        # let's get the outputs of each attention head\n",
    "        # list length h of tuples length g of tensors shape (b,t,h_i) for h_i=d_i/h where d_i=nesting_list[i]\n",
    "        head_outputs = [head(x) for head in self.headsList]\n",
    "\n",
    "        # now let's reformat our ugly list of tuples into our usual expected tuple legnth g containing tensors shape (b,t,d_i)\n",
    "        mid = ()\n",
    "        for i in range(self.d_count):\n",
    "            level = [] # where will store the output of each head for this size d_i\n",
    "            for j, head in enumerate(head_outputs):\n",
    "                level.append(head[i]) # this head's output for the d_i layer of the model\n",
    "            \n",
    "            # appending the concatenation of all the heads for this d_i layer of the model\n",
    "            mid += (torch.cat(level, dim=-1),) # tuple length g with tensors of shape (b,t,d_i) for d_i=nesting_list[i]\n",
    "            #print(f\"mha_before_projection[{i}]: \", mid[i].shape)\n",
    "\n",
    "        # now let's do our linear projection, which is not similar to how we did the matryoshkaFeedForward()\n",
    "        # because we can't just select nested matrices within the primary matrix, we also have to account for the head concatenation\n",
    "        # and this means skipping throughout and grabbing specific parts from the projection that match up\n",
    "        #\n",
    "        # so along the vertical of the matrix we want to iterate through self.nesting_list \n",
    "        # and along the horizontal we need to make skips the size of self.h the largest head\n",
    "        # and then from those skips as starting points iteratively slice using self.head_sizes\n",
    "        # then we concatenate those multiple spliced pieces along the horizontal\n",
    "        # then we multiply a given output level by its respective projection\n",
    "        out = ()\n",
    "        for i, (d_i, h_i) in enumerate(zip(self.nesting_list, self.head_sizes)):\n",
    "            skip = j*self.h_max\n",
    "            # h_i is the head size of this iteration\n",
    "            this_levels_proj_w = torch.cat([self.weight[skip:skip+h_i,:d_i] for j in range(self.h_count)], dim=0)\n",
    "\n",
    "            # bias is only one dimension so a bit simpler\n",
    "            this_levels_proj_b = torch.cat([self.bias[skip:skip+h_i] for j in range(self.h_count)])\n",
    "\n",
    "            # select correct level & multiply by weights then add bias\n",
    "            # and can't forget to dropout\n",
    "            out += (self.dropout(mid[i]@this_levels_proj_w + this_levels_proj_b),)\n",
    "            #print(f\"mha_after_projection[{i}]: \", out[i].shape)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66f9d9c9-2ed5-47d1-950f-f138d1acb613",
   "metadata": {},
   "outputs": [],
   "source": [
    "class matryoshkaMultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, h, nesting_list: List, head_sizes: List, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.nesting_list = nesting_list\n",
    "        self.head_sizes = head_sizes\n",
    "        self.h_count = h # number of heads\n",
    "        self.d_count = len(nesting_list) # number of nesting doll sizes\n",
    "        self.h_max = head_sizes[-1] # size of largest head\n",
    "        self.d_max = nesting_list[-1]\n",
    "        \n",
    "        # can you have tuples inside a module list? i hope so\n",
    "        self.headsList = nn.ModuleList([matryoshkaHead(self.nesting_list, self.head_sizes) for _ in range(self.h_count)])\n",
    "        \n",
    "        #self.proj = nn.Linear(head_sizes[-1] * h, nesting_list[-1])\n",
    "        # the linear projection that combines the outputs of all the heads\n",
    "        self.weight = nn.Parameter(torch.Tensor(self.h_max * self.h_count, self.d_max)).to(device)\n",
    "        self.bias = nn.Parameter(torch.Tensor(self.h_max * self.h_count)).to(device)\n",
    "        \n",
    "        # Initializing parameters\n",
    "        nn.init.normal_(self.weight, std=0.02)  \n",
    "        nn.init.normal_(self.bias, std=0.02)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forwardTuple(self, x):\n",
    "        \"\"\"\n",
    "        input: tuple of length g with tensors of shape (b,t,d_i) for d_i=nesting_list[i]\n",
    "        operation: \n",
    "            - perform self-attention w each head & then concatenate & linearly project\n",
    "            - input to each head: tuple of length g with tensors of shape (b,t,d_i) for d_i=nesting_list[i]\n",
    "            - output from each head: tuple length g with tensors of shape (b,t,h_i) for h_i=head_sizes[i] where h_i = d_i / h\n",
    "        output: tuple of length g with tensors of shape (b,t,d_i) for d_i=nesting_list[i]\n",
    "        \"\"\"\n",
    "        # let's get the outputs of each attention head\n",
    "        # list length h of tuples length g of tensors shape (b,t,h_i) for h_i=d_i/h where d_i=nesting_list[i]\n",
    "        head_outputs = [head(x) for head in self.headsList]\n",
    "\n",
    "        # now let's reformat our ugly list of tuples into our usual expected tuple legnth g containing tensors shape (b,t,d_i)\n",
    "        mid = ()\n",
    "        for i in range(self.d_count):\n",
    "            level = [] # where will store the output of each head for this size d_i\n",
    "            for j, head in enumerate(head_outputs):\n",
    "                level.append(head[i]) # this head's output for the d_i layer of the model\n",
    "            \n",
    "            # appending the concatenation of all the heads for this d_i layer of the model\n",
    "            mid += (torch.cat(level, dim=-1),) # tuple length g with tensors of shape (b,t,d_i) for d_i=nesting_list[i]\n",
    "\n",
    "        # now let's do our linear projection, which is not similar to how we did the matryoshkaFeedForward()\n",
    "        # because we can't just select nested matrices within the primary matrix, we also have to account for the head concatenation\n",
    "        # and this means skipping throughout and grabbing specific parts from the projection that match up\n",
    "        #\n",
    "        # so along the vertical of the matrix we want to iterate through self.nesting_list \n",
    "        # and along the horizontal we need to make skips the size of self.h the largest head\n",
    "        # and then from those skips as starting points iteratively slice using self.head_sizes\n",
    "        # then we concatenate those multiple spliced pieces along the horizontal\n",
    "        # then we multiply a given output level by its respective projection\n",
    "        out = ()\n",
    "        for i, (d_i, h_i) in enumerate(zip(self.nesting_list, self.head_sizes)):\n",
    "            # h_i is the head size of this iteration\n",
    "            this_levels_proj_w = torch.cat([self.weight[j*self.h_max:j*self.h_max+h_i,:d_i] for j in range(self.h_count)], dim=0)\n",
    "\n",
    "            # bias is only one dimension so a bit simpler\n",
    "            this_levels_proj_b = torch.cat([self.bias[j*self.h_max:j*self.h_max+h_i] for j in range(self.h_count)])\n",
    "\n",
    "            # select correct level & multiply by weights then add bias\n",
    "            # and can't forget to dropout\n",
    "            out += (self.dropout(mid[i]@this_levels_proj_w + this_levels_proj_b),)\n",
    "            \n",
    "        return out\n",
    "\n",
    "    def forwardTensor(self, x, d_i):\n",
    "        \"\"\"\n",
    "        input: \n",
    "            - tensor of shape (b,t,d_i)\n",
    "            - dimension to use d_i\n",
    "            - number of heads h\n",
    "        operation: \n",
    "            - perform self-attention w each head & then concatenate & linearly project\n",
    "            - input to each head: tensor of shape (b,t,d_i)\n",
    "            - output from each head: tensor of shape (b,t,h_i) where h_i = d_i / h\n",
    "        output: tensor of shape (b,t,d_i) \n",
    "        \"\"\"\n",
    "        if d_i is None:\n",
    "            d_i = x.shape[-1]\n",
    "            \n",
    "        # gives us a tensor shape (b,t,d_i)\n",
    "        head_outputs = torch.cat([head(x, d_i=d_i, h=self.h_count) for head in self.headsList], dim=-1)\n",
    "\n",
    "        spliced_projection_w = torch.cat([self.weight[j*self.h_max:j*self.h_max+h_i,:d_i] for j in range(self.h_count)], dim=0)\n",
    "        spliced_projection_b = torch.cat([self.bias[j*self.h_max:j*self.h_max+h_i] for j in range(self.h_count)])\n",
    "\n",
    "        return self.dropout(head_outputs @ spliced_projection_w + spliced_projection_b)\n",
    "        \n",
    "    def forward(self, x, d_i=None):\n",
    "        return self.forwardTuple(x) if type(x) == tuple else self.forwardTensor(x, d_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858ce12c-b033-475e-bfd6-bb598cc9ffb8",
   "metadata": {},
   "source": [
    "# LAYERNORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c6283f2-b2da-493e-b35d-4b8b40c2c5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class matryoshkaLayerNorm(nn.Module):\n",
    "    def __init__(self, nesting_list: List):\n",
    "        super().__init__()\n",
    "\n",
    "        self.nesting_list = nesting_list\n",
    "        self.d_count = len(nesting_list)\n",
    "\n",
    "        # we need layernorm attributes for each dimension size\n",
    "        for d_i in nesting_list:\n",
    "            setattr(self, f\"ln_{d_i}\", nn.LayerNorm(d_i, elementwise_affine=False)) \n",
    "        \n",
    "    def forward(self, x, d_i=None):\n",
    "        \"\"\"\n",
    "        a layernorm module that is dynamic to the input of either a single tensor or a tuple of tensors\n",
    "        only works if the dimensions in question are in self.nesting_list\n",
    "\n",
    "        input: either \n",
    "        - a tensor with last dimension equal to some value in self.nesting_list\n",
    "        - a tuple of tensors where the last dimensions of each matches the values in self.nesting_list IN ORDER\n",
    "\n",
    "        output: either of the above, but normalized\n",
    "\n",
    "        NOTE: later i might do a weird scheme where it layernorms the smallest embedding dimension first, then holds that constant\n",
    "        and layernorms all the remaining values in the next sized embedding dimension, and then so on. this might help w stability\n",
    "        depending on how the rest of the model ends up looking\n",
    "        \"\"\"\n",
    "        #print(\"layernorm\")\n",
    "        if type(x) == tuple:\n",
    "            out = ()\n",
    "            for i, d_i in enumerate(self.nesting_list): # i hop\n",
    "                out += (getattr(self, f\"ln_{d_i}\")(x[i]),)\n",
    "        else: #if type(x) == torch.Tensor:\n",
    "            #print(\"the layernorm was NOT a tuple\")\n",
    "            if d_i is None:\n",
    "                d_i = x.shape[-1]\n",
    "            out = getattr(self, f\"ln_{d_i}\")(x)\n",
    "            #print(\"out: \", out.shape)\n",
    "        #else:\n",
    "            #print(\"ERROR: LAYERNORM NEEDED TUPLE or TENSOR BUT RECEIVED \", type(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b81d0c-d679-44e7-acf2-ff40e3276316",
   "metadata": {},
   "source": [
    "# BLOCK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a98e38-113f-4c42-8696-af7405602791",
   "metadata": {},
   "source": [
    "class matryoshkaBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer block: communication followed by computation\n",
    "    \n",
    "    input: length g tuple of shape (b,t,d_i) tensors for d_i in nesting_list\n",
    "    output: length g tuple of shape (b,t,d_i) tensors for d_i in nesting_list\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, h, nesting_list: List, dropout):\n",
    "        # d: the biggest embedding dimension, h: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        \n",
    "        self.nesting_list = nesting_list\n",
    "        self.head_sizes = [d_i // h for d_i in nesting_list] # the second / forces the value to be an int isntead of a float\n",
    "        \n",
    "        self.norm = matryoshkaLayerNorm(nesting_list)\n",
    "        self.mha = matryoshkaMultiHeadAttention(h, nesting_list, self.head_sizes, dropout) \n",
    "        self.ffwd = matryoshkaFeedFoward(nesting_list, dropout)\n",
    "        \n",
    "        # originals\n",
    "        #head_size = d // h # the double backslash just makes the output an int instead of float\n",
    "        #self.ln = nn.LayerNorm(d, elementwise_affine=False)\n",
    "    \n",
    "    def forward(self, x_i):\n",
    "        #print(\"block\")\n",
    "        #print(\"head_sizes: \", self.head_sizes)\n",
    "        #x = x_i + self.mha(self.ln(x_i))\n",
    "        #x = x + self.ffwd(self.ln(x))\n",
    "\n",
    "        x_iplus1quart = self.norm(x_i)\n",
    "        #print(\"x_iplus1quart: \", x_iplus1quart[0].shape, x_iplus1quart[1].shape)\n",
    "        \n",
    "        attn = self.mha(x_iplus1quart)\n",
    "\n",
    "        x_iplus1half = ()\n",
    "        for j in range(len(self.nesting_list)):\n",
    "            x_iplus1half += (x_i[j] + attn[j],)\n",
    "\n",
    "        x_iplus3quart = self.norm(x_iplus1half)\n",
    "\n",
    "        ffwd = self.ffwd(x_iplus3quart)\n",
    "\n",
    "        x_iplus1 = ()\n",
    "        for j in range(len(self.nesting_list)):\n",
    "            x_iplus1 += (x_iplus1half[j] + ffwd[j],)\n",
    "\n",
    "        # i can make this all prettier later by changing every single function to either take in a tensor or a tuple\n",
    "        # i think at that point i might be able to reuse the code below \\/\n",
    "\n",
    "        #x_iplus1quart, x_iplus1half, x_iplus3quart, x_iplus1 = (), (), (), ()\n",
    "        #for j, d_j in enumerate(self.nesting_list):\n",
    "            #x_iplus1quart += (self.norm(x_i[j]),)\n",
    "            #x_iplus1half += (x_i[j] + self.mha(x_iplus1quart[j]),)\n",
    "            #x_iplus3quart += (self.norm(x_iplus1half[j]),)\n",
    "            #x_iplus1 += (x_iplus1half[j]  + self.ffwd(x_iplus3quart[j]),)\n",
    "        # this is so inefficient it's absurd\n",
    "            \n",
    "        return x_iplus1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ea698c4-6869-4dc3-a5f6-64f357be2fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class matryoshkaBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer block: communication followed by computation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, h, nesting_list: List, dropout):\n",
    "        # d: the biggest embedding dimension, h: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        \n",
    "        self.nesting_list = nesting_list\n",
    "        self.head_sizes = [d_i // h for d_i in nesting_list] # the second / forces the value to be an int isntead of a float\n",
    "        \n",
    "        self.ln = matryoshkaLayerNorm(nesting_list)\n",
    "        self.mha = matryoshkaMultiHeadAttention(h, nesting_list, self.head_sizes, dropout) \n",
    "        self.ffwd = matryoshkaFeedFoward(nesting_list, dropout)\n",
    "    \n",
    "    def forwardTuple(self, x_i):\n",
    "        \"\"\"\n",
    "        input: length g tuple of shape (b,t,d_i) tensors for d_i in nesting_list\n",
    "        output: length g tuple of shape (b,t,d_i) tensors for d_i in nesting_list\n",
    "        \"\"\"\n",
    "\n",
    "        x_iplus1quart = self.ln(x_i)\n",
    "        \n",
    "        attn = self.mha(x_iplus1quart)\n",
    "\n",
    "        #x_iplus1half = ()\n",
    "        #for j in range(len(self.nesting_list)):\n",
    "            #x_iplus1half += (x_i[j] + attn[j],)\n",
    "        x_iplus1half = tuple(x_i[j] + attn[j] for j in range(len(self.nesting_list)))\n",
    "\n",
    "        x_iplus3quart = self.ln(x_iplus1half)\n",
    "\n",
    "        ffwd = self.ffwd(x_iplus3quart)\n",
    "\n",
    "        #x_iplus1 = ()\n",
    "        #for j in range(len(self.nesting_list)):\n",
    "            #x_iplus1 += (x_iplus1half[j] + ffwd[j],)\n",
    "        x_iplus1 = tuple(x_iplus1half[j] + ffwd[j] for j in range(len(self.nesting_list)))\n",
    "            \n",
    "        return x_iplus1\n",
    "\n",
    "    def forwardTensor(self, x, d_i): # need to figure out what i'm doing w default values of d_i & passing them through\n",
    "        \"\"\"\n",
    "        input: tensor of shape (b,t,d_i)\n",
    "        output: tensor of shape (b,t,d_i)\n",
    "        \"\"\"\n",
    "        return x + self.ffwd(self.ln(x + self.mha(self.ln(x))))\n",
    "        \n",
    "    def forward(self, x, d_i=None):\n",
    "        return self.forwardTuple(x) if type(x) == tuple else self.forwardTensor(x, d_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900569c1-bdac-4b68-ab21-1f94238bcad4",
   "metadata": {},
   "source": [
    "# OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac2d6119-7155-4c7a-8e3c-8cdfd817d67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class matryoshkaOutputLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    the output layer. we've gotta layernorm each size then use the transposed embedding matrix as our linear layer to multiply by\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding, nesting_list: List, num_classes): # , **kwargs # <- not sure why that was an argument\n",
    "        super().__init__() # matryoshkaOutputLayer, self # <- not sure why those were inside super()\n",
    "        self.nesting_list = nesting_list\n",
    "        self.num_classes = num_classes  # Number of classes for classification\n",
    "        \n",
    "        self.embedding = embedding  # Store reference to the embedding layer\n",
    "\n",
    "        self.norm = matryoshkaLayerNorm(nesting_list)\n",
    "            \n",
    "        # Initialize layer normalization\n",
    "        #self.layer_norm = nn.LayerNorm(nesting_list[-1], elementwise_affine=False)\n",
    "\n",
    "    def forwardTuple(self, x):\n",
    "        \"\"\"\n",
    "        input: length g tuple of tensors shape (b,t,d_i) for d_i in nesting_list\n",
    "        operation: multiply the final residual state by the embedding vectors to get final logits\n",
    "        output: length g tuple of tensors shape (b,t,v) where v is token vocabulary length\n",
    "        \"\"\"\n",
    "        #print(\"output\")\n",
    "        normed_logits = self.norm(x)\n",
    "        #print(\"normed_logits: \", normed_logits[0].shape, normed_logits[1].shape)\n",
    "        normed_embeddings = self.norm(self.embedding).t()#.to(device) # can i put this in the __init__???\n",
    "        #print(\"normed_embeddings: \", normed_embeddings.shape)\n",
    "        \n",
    "        out = ()\n",
    "        for i, d_i in enumerate(self.nesting_list):\n",
    "            out += (normed_logits[i] @ normed_embeddings[:d_i,:],) \n",
    "            \n",
    "        return out\n",
    "\n",
    "    def forwardTensor(self, x, d_i):\n",
    "        \"\"\"\n",
    "        input: tensor shape (b,t,d_i)\n",
    "        operation: multiply the final residual state by the embedding vectors to get final logits\n",
    "        output: tensor shape (b,t,v) where v is token vocabulary length\n",
    "        \"\"\"\n",
    "        if d_i is None:\n",
    "            d_i = x.shape[-1]\n",
    "        normed_logits = self.norm(x, d_i)\n",
    "        normed_embeddings = self.norm(self.embedding, d_i).t()\n",
    "        return normed_logits @ normed_embeddings[:d_i,:]\n",
    "        \n",
    "    def forward(self, x, d_i=None):\n",
    "        return self.forwardTuple(x) if type(x) == tuple else self.forwardTensor(x, d_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25841de5-cec6-430c-aacd-e8264e0cfc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class matryoshkaCEL(nn.Module):\n",
    "    '''\n",
    "    Loss function for Matryoshka Representation Learning\n",
    "    we don't need to create a tensor version of the loss function bc training always involves all nesting levels\n",
    "    '''\n",
    "    def __init__(self, relative_importance: List[float]=None): #, **kwargs\n",
    "        super().__init__() # matryoshkaCEL, self # not sure why those were in super()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # relative importance shape: [G]\n",
    "        # this is optional for if you want to weight them differently\n",
    "        self.relative_importance = relative_importance\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        # logits are a length g tuple each of shape [b batch size, t sequence length, v number of classes]\n",
    "        # target shape: [b batch size, t sequence length]\n",
    "        #print(\"loss\")\n",
    "        g = len(logits)\n",
    "        b,t,v = logits[0].shape\n",
    "\n",
    "        # Calculate losses for each output and stack them\n",
    "        # might need to do .view() or .reshape() to make sure these go in well\n",
    "        losses = torch.stack([self.criterion(logits_i.view(b*t, v), target.view(b*t)) for logits_i in logits])\n",
    "        #print(\"losses: \", losses)\n",
    "\n",
    "        # Set relative_importance to 1 if not specified\n",
    "        # I don't think i'm gonna be messing around with this part\n",
    "        rel_importance = torch.ones_like(losses) if self.relative_importance is None else torch.tensor(self.relative_importance)\n",
    "\n",
    "        # Apply relative importance weights\n",
    "        weighted_losses = rel_importance * losses\n",
    "        return weighted_losses.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74340f6-6a3d-44b9-8282-0966e5a30d5a",
   "metadata": {},
   "source": [
    "# THE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46ec707-a54f-411a-815c-9692b83d7654",
   "metadata": {},
   "source": [
    "# -------------------- BOOKMARK -----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a739ac90-fd72-499e-997c-f831ba201042",
   "metadata": {},
   "outputs": [],
   "source": [
    "class matryoshkaGPT(nn.Module):\n",
    "    def __init__(self, nesting_list: List, v, t, h, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        # the list of dimensions we'll be using\n",
    "        self.nesting_list = nesting_list\n",
    "        \n",
    "        # the largest embedding size\n",
    "        self.d = nesting_list[-1]\n",
    "        \n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(v, self.d).to(device)\n",
    "        \n",
    "        # simple learned positional encodings rather than sine or RoPE\n",
    "        self.position_embedding_table = nn.Embedding(t, self.d).to(device)\n",
    "        self.context_len = t\n",
    "\n",
    "        # our special implementation of layernorm\n",
    "        self.ln = matryoshkaLayerNorm(nesting_list)\n",
    "\n",
    "        # bulk of the beast\n",
    "        self.blocks = nn.Sequential(*[matryoshkaBlock(h, nesting_list, dropout) for _ in range(l)]) \n",
    "\n",
    "        ### MATRYOSHKA OUTPUT HEADS\n",
    "        self.out_heads = matryoshkaOutputLayer(self.token_embedding_table.weight, nesting_list, num_classes=v)\n",
    "        \n",
    "        ### MATRYOSHKA LOSS\n",
    "        self.loss = matryoshkaCEL()\n",
    "\n",
    "    def forward(self, idx, targets=None, desired_d=nesting_list[-1]): # should i change from d_i to desired_d or degree?\n",
    "        #print(\"forward\")\n",
    "        \n",
    "        b, t = idx.shape\n",
    "        \n",
    "        # idx and targets are both (b,t) tensor of integers\n",
    "        pos_emb = self.position_embedding_table(torch.arange(t, device=device)) # (t,d)\n",
    "        #print(\"pos_emb: \", pos_emb.shape)\n",
    "        tok_emb = self.token_embedding_table(idx) # (b,t,d)\n",
    "        #print(\"tok_emb: \", tok_emb.shape)\n",
    "    \n",
    "        if targets is None:\n",
    "            # send in a single matrix using d_i\n",
    "            x_0 = self.ln(tok_emb[:,:desired_d]) + pos_emb[...,:desired_d] # (b,t,d) + (t,d) = (b,t,d)\n",
    "        else:\n",
    "            # create tuple & send thru\n",
    "            # our first nested thingy\n",
    "            x_0 = ()\n",
    "            for d_i in self.nesting_list:\n",
    "                # notice how we're layernorming the specific size not the whole thing\n",
    "                x_0 += (self.ln(tok_emb[...,:d_i]) + pos_emb[...,:d_i],) # (b,t,d) + (t,d) = (b,t,d)\n",
    "            # so in total the for loop gives us (b,t,d) & (t,d) -> g*(b,t,d_i) for d_i in nesting_list\n",
    "            #print(\"x_0: \", x_0[0].shape, x_0[1].shape)\n",
    "\n",
    "        x_f = self.blocks(x_0)\n",
    "\n",
    "        # Matryoshka output head\n",
    "        # self.out_heads includes within it the final layernorm\n",
    "        logits = self.out_heads(x_f, desired_d)\n",
    "\n",
    "        loss = None if targets is None else self.loss(logits, targets) # g*(b,t,d) & (b,t) -> float\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens=100, degree=-1):\n",
    "        \"\"\"\n",
    "        input: idx is (b, ?) tensor of indices from the current context\n",
    "        output: idx is (b,?+max_new_tokens) tensor of indices\n",
    "        \"\"\"\n",
    "        assert degree >= -1 & degree < len(nesting_list)\n",
    "        desired_d = nesting_list[degree]\n",
    "        \n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -self.context_len:]\n",
    "            \n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond, desired_d)\n",
    "            \n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (b, d)\n",
    "            \n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (b, d)\n",
    "            \n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (b, 1)\n",
    "            \n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (b, t+1)\n",
    "            \n",
    "        return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d1bf3d-d8a3-4740-b0fd-5194150d175e",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9dc28cb-bf08-4b71-9f78-9d6ffd05b2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203.328 K parameters\n"
     ]
    }
   ],
   "source": [
    "model = matryoshkaGPT(nesting_list, v, t, h, dropout).to(device)\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=l2)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in model.parameters())/1e3, 'K parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "723a095c-dbf7-40bf-8f0d-9e0ec3b29c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 87.8798, val loss 87.4281, time elapsed: 0.16 seconds\n",
      "step 2: train loss 86.5723, val loss 87.2444, time elapsed: 0.84 seconds\n",
      "step 4: train loss 86.3342, val loss 85.4267, time elapsed: 1.79 seconds\n",
      "step 6: train loss 84.8918, val loss 86.2133, time elapsed: 2.50 seconds\n",
      "step 8: train loss 85.2517, val loss 84.6767, time elapsed: 3.17 seconds\n",
      "step 9: train loss 83.8832, val loss 83.8974, time elapsed: 3.94 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Enable anomaly detection\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    # train\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        current_time = time.time()\n",
    "        elapsed_time = current_time - start_time\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}, time elapsed: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Disable anomaly detection after the training loop\n",
    "#torch.autograd.set_detect_anomaly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "048a11fd-f2d1-4904-9cd3-f4e04ce9478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the trained model\n",
    "torch.save(model.state_dict(), f'models/{model.__class__.__name__}_b{b}_t{t}_d{d}_h{h}_l{l}_lr{lr}_drop{dropout}_l2-{l2}_min_power{min_power}_{time.strftime(\"%Y-%m-%d|%H-%M-%S\")}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad7bd4c-918b-4e06-9354-d7b94b236705",
   "metadata": {},
   "source": [
    "# Load a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f0662-f989-4756-afe4-d36018223359",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = matryoshka GPT().to(device)  # Initialize a model with the same architecture\n",
    "\n",
    "# Load the saved state dictionary\n",
    "model.load_state_dict(torch.load('models/GPT_b24_t128_d128_h8_l8_lr0.0003_drop0.2_l2-0.01_2024-01-25|23-31-12.pth'))\n",
    "\n",
    "# If you plan to continue training the model, switch to training mode\n",
    "#model.train()\n",
    "\n",
    "# If you only plan to do inference, switch to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fa6025-71cd-40de-bd8e-0d4d7b55cf2b",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "34e44c0a-1b73-4d69-b730-b02dcd572264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[22, 33, 24, 21, 17, 32, 10,  0, 27,  1, 30, 53, 51, 43, 53,  6,  1, 30,\n",
      "         53, 51, 43, 53,  2,  1, 61, 46, 43, 56, 43, 44, 53, 56, 43,  1, 39, 56,\n",
      "         58,  1, 58, 46, 53, 59,  1, 30]])\n"
     ]
    }
   ],
   "source": [
    "input_str = \"JULIET:\\nO Romeo, Romeo! wherefore art thou R\" # the classic line\n",
    "context_tensor = torch.tensor([encode(input_str)], dtype=torch.long, device=device)\n",
    "print(context_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1570cebd-3548-4cba-97bf-1b12ceb37c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JULIET:\n",
      "O Romeo, Romeo! wherefore art thou RS\n",
      "M ana  na bsE a &&&& \n",
      "ucenl; tabannheUa h t man cyy ey g ann the th b mo t be te awe le t Wka, rer\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(context_tensor, max_new_tokens=100)\n",
    "output_str = decode(output[0].tolist())\n",
    "print(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc41efef-37e8-4c26-a853-e9d861da6da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
